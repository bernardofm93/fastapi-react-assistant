# ğŸ§  FastAPI ReAct Assistant
![Python Version](https://img.shields.io/badge/Python-3.10%2B-blue)
![FastAPI Version](https://img.shields.io/badge/FastAPI-0.115.13-green)
![LangChain](https://img.shields.io/badge/LangChain-0.3.26-purple)
![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-orange)

Assistente Conversacional que utiliza um **Agente ReAct** para responder perguntas sobre produtos e SAC, combinando **consulta em SQL** e/ou **busca semÃ¢ntica**.  
O projeto inclui:

âœ… **FastAPI** como backend HTTP  
âœ… **LangGraph + LangChain** para criaÃ§Ã£o do agente ReAct  
âœ… **Ollama** como servidor local de modelos LLM e embeddings  
âœ… **ChromaDB** como banco vetorial do SAC e dos nomes dos produtos  
âœ… **SQLite** para persistir histÃ³rico de conversas e armazenar o catÃ¡logo de produtos

---

ğŸ§© VisÃ£o Geral

O projeto implementa um Agente ReAct que combina raciocÃ­nio e aÃ§Ãµes a partir de diferentes fontes de dados para responder perguntas relacionadas ao catÃ¡logo e ao serviÃ§o de atendimento ao cliente da C&A.

â¸»

ğŸ–¼ï¸ Arquitetura do Agente

A arquitetura de um agente ReAct pode ser representada por um grafo, contendo um nodo de assistente e outro de ferramentas, conforme imagem abaixo. 

![alt text](image.png)

O agente ReAct segue a seguinte lÃ³gica:
	1.	Recebe a pergunta do usuÃ¡rio
	2.	Analisa o contexto e o histÃ³rico
	3.	Decide quais ferramentas utilizar
	4.	Executa buscas SQL ou semÃ¢nticas
	5.	Combina e organiza a resposta final


â¸»

ğŸ› ï¸ Ferramentas Utilizadas

O agente conta com duas ferramentas principais:

- Busca SQL de Produtos do catÃ¡logo: Realiza consultas estruturadas na base de dados SQLite para retornar informaÃ§Ãµes detalhadas sobre produtos, como preÃ§o, tÃ­tulo e descriÃ§Ã£o.
- Busca SemÃ¢ntica de Produtos e SAC: Banco vetorial criado com o ChromaDB, utilizando um modelo local de embeddings do Ollama. Foram criadas duas collections distintas:
 	- CatÃ¡logo: Nos casos em que o cliente nÃ£o sabe o nome exato de um produto, realiza a busca por similaridade semÃ¢ntica entre a necessidade informada pelo cliente e 	as descriÃ§Ãµes dos produtos;
 	- SAC: Usado para recuperar respostas Ã s perguntas mais frequentes sobre o ServiÃ§o de Atendimento ao Consumidor, incluindo assuntos como polÃ­ticas de reembolso, 	prazos de entrega e devoluÃ§Ã£o/troca de produtos.

â¸»


## ğŸ–¥ï¸ :computer: Requisitos

- :snake: [**Python 3.10+**](https://www.python.org/downloads/)
- :whale: [**Docker**](https://www.docker.com/products/docker-desktop/)
- [**Ollama**](https://ollama.com/download) (Para rodar modelos de LLM e embeddings)


â¸»

ğŸƒ :pushpin: Rodando localmente

Antes de tudo, certifique-se de que o Ollama estÃ¡ rodando e de que os modelos foram baixados.


ğŸ“¥ Clone o repositÃ³rio

        git clone https://github.com/bernardofm93/fastapi-react-assistant.git


â¸»

ğŸ§° Instale as dependÃªncias

        python -m venv .venv
        source .venv/bin/activate
        pip install -r requirements.txt


â¸»

ğŸ¤– Baixe modelos no Ollama

        ollama pull llama3.1
        ollama pull granite-embeddings:278m


â¸»

ğŸ—ƒï¸ Preprocessamento inicial

Gera o banco de produtos (produtos.db) e popula o ChromaDB com embeddings:

        python -m app.db.preprocess


â¸»

ğŸš€ Suba a API

        uvicorn app.main:app --reload

Por padrÃ£o, estarÃ¡ disponÃ­vel em:

http://localhost:8000


â¸»

ğŸ“š Endpoints

ğŸ”¹ POST /chat/

Envia uma pergunta e recebe a resposta do assistente.

Exemplo de Request body:

        {
        "question": "Quais calÃ§as custam menos de 200 reais?",
        "thread_id": "thread-123"
        }


â¸»

ğŸ”¹ GET /historico/{thread_id}

Recupera todo o histÃ³rico da conversa a partir do ID da thread.


â¸»

ğŸ”¹ Swagger Docs

Interface interativa:

http://localhost:8000/docs


â¸»

ğŸ³ :whale: Docker

Rodando via Docker Compose.

â¸»

ğŸ› ï¸ Build da imagem

        docker build -t fastapi-react-assistant .


â¸»

ğŸš€ Run com Docker

Certifique-se que o Ollama estÃ¡ rodando no host e passe o .env:

        docker run -d --env-file .env -p 8000:8000 --name assistant fastapi-react-assistant


â¸»


ğŸ§  Exemplos de uso com cURL

Enviar pergunta:

        curl -X POST "http://localhost:8000/chat/" \
        -H "Content-Type: application/json" \
        -d '{"question":"Quantos produtos custam abaixo de 200 reais?","thread_id":"teste"}'

Consultar histÃ³rico:

        curl "http://localhost:8000/historico/teste


â¸»

ğŸ““ ğŸ§ª Testando em Jupyter Notebook

Caso seja mais acessÃ­vel, Ã© possÃ­vel realizar o teste no arquivo **teste_agente.ipynb**. 
